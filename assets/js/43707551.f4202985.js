"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3999],{37243:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var n=a(74848),s=a(28453);const i={slug:"kafka-streams-state-stores",title:"Kafka Streams - Why you should use named state stores",authors:"javier",tags:["kafka-streams","kafka","state-store"]},o="Kafka Streams - Named state stores",r={permalink:"/blog/kafka-streams-state-stores",editUrl:"https://github.com/JavierMonton/blog/edit/main/website/blog/2025-07-13-kafka-streams-named-state-stores/index.md",source:"@site/blog/2025-07-13-kafka-streams-named-state-stores/index.md",title:"Kafka Streams - Why you should use named state stores",description:"Why should you name your state stores?",date:"2025-07-13T00:00:00.000Z",formattedDate:"July 13, 2025",tags:[{label:"kafka-streams",permalink:"/blog/tags/kafka-streams"},{label:"kafka",permalink:"/blog/tags/kafka"},{label:"state-store",permalink:"/blog/tags/state-store"}],readingTime:6.455,hasTruncateMarker:!1,authors:[{name:"Javier Mont\xf3n",title:"Software Engineer",url:"https://github.com/JavierMonton",imageURL:"https://github.com/JavierMonton.png",key:"javier"}],frontMatter:{slug:"kafka-streams-state-stores",title:"Kafka Streams - Why you should use named state stores",authors:"javier",tags:["kafka-streams","kafka","state-store"]},unlisted:!1,nextItem:{title:"Kafka Connect - Protobuf Converters",permalink:"/blog/kafka-connect-protobuf"}},l={authorsImageUrls:[void 0]},c=[{value:"State Stores",id:"state-stores",level:2},{value:"Internal Topics",id:"internal-topics",level:2},{value:"Changelog Topics",id:"changelog-topics",level:3},{value:"Repartition Topics",id:"repartition-topics",level:3},{value:"Code Examples",id:"code-examples",level:2},{value:"Naming State Stores",id:"naming-state-stores",level:2},{value:"Benefits of Named State Stores",id:"benefits-of-named-state-stores",level:3},{value:"TL;DR",id:"tldr",level:2}];function d(e){const t={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Why should you name your state stores?"}),"\nBecause otherwise, you'll lose data."]}),"\n",(0,n.jsx)(t.p,{children:"But first, a bit of context."}),"\n",(0,n.jsx)(t.h1,{id:"kafka-streams",children:"Kafka Streams"}),"\n",(0,n.jsx)(t.p,{children:"Kafka Streams is a client library for building applications and microservices where the input and output data are stored in Kafka clusters.\nIt combines the simplicity of writing and deploying standard Java and Scala applications on the client side with the benefits of Kafka's server-side cluster technology."}),"\n",(0,n.jsx)(t.p,{children:"Unlike other stream processing frameworks, Kafka Streams is not a separate processing cluster but a library that runs within your application.\nThis means you don't need to set up and manage a separate cluster - your application becomes the stream processing engine."}),"\n",(0,n.jsx)(t.p,{children:"Kafka Streams gives you simple operations like:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"map"})," - transform each record"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"filter"})," - keep only records that match certain conditions"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"join"})," - combine data from different sources"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.code,{children:"aggregate"})," - group and summarize data"]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"It also handles the hard stuff automatically, like recovering from failures and making sure data isn't lost or processed twice."}),"\n",(0,n.jsx)(t.h2,{id:"state-stores",children:"State Stores"}),"\n",(0,n.jsx)(t.p,{children:"State stores are a fundamental concept in Kafka Streams that allow you to maintain local state within your stream processing application.\nThey are essentially key-value stores that are backed by Kafka topics for durability and fault tolerance."}),"\n",(0,n.jsxs)(t.p,{children:["By default, you don't need to think much about them, Kafka Streams automatically creates and manages state stores for you when you use operations like ",(0,n.jsx)(t.code,{children:"groupBy"}),", ",(0,n.jsx)(t.code,{children:"aggregate"}),", or ",(0,n.jsx)(t.code,{children:"join"}),"."]}),"\n",(0,n.jsx)(t.p,{children:"State stores are automatically managed by Kafka Streams, including:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Persistence to local disk (RocksDB by default)"}),"\n",(0,n.jsx)(t.li,{children:"Backup to Kafka topics (changelog topics)"}),"\n",(0,n.jsx)(t.li,{children:"Restoration during application restarts"}),"\n",(0,n.jsx)(t.li,{children:"Rebalancing when scaling up/down"}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["As an example, a common scenario is when you want to performa a join between two streams. One way of doing it is to use a ",(0,n.jsx)(t.code,{children:"KTable"}),", which is a representation of a stream as a table.\nWhen you create a ",(0,n.jsx)(t.code,{children:"KTable"})," from a topic, Kafka Streams automatically creates a state store to maintain the current state of that table. Then, you can join a ",(0,n.jsx)(t.code,{children:"KStream"})," with a ",(0,n.jsx)(t.code,{children:"KTable"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["When joining a ",(0,n.jsx)(t.code,{children:"KStream"})," with a ",(0,n.jsx)(t.code,{children:"KTable"}),", Kafka Streams will perform the join for each record in the ",(0,n.jsx)(t.code,{children:"KStream"})," against the current state of the ",(0,n.jsx)(t.code,{children:"KTable"}),"."]}),"\n",(0,n.jsx)(t.admonition,{type:"warning",children:(0,n.jsxs)(t.p,{children:["This means that if the ",(0,n.jsx)(t.code,{children:"KTable"})," is not up to date, or if it missing data for any reason, the join might not produce the expected results."]})}),"\n",(0,n.jsx)(t.h2,{id:"internal-topics",children:"Internal Topics"}),"\n",(0,n.jsx)(t.p,{children:"When you use stateful operations in Kafka Streams, the framework automatically creates internal topics in Kafka to support fault tolerance and state management.\nThese topics are not meant to be consumed directly by other applications."}),"\n",(0,n.jsx)(t.p,{children:"The main types of internal topics are:"}),"\n",(0,n.jsx)(t.h3,{id:"changelog-topics",children:"Changelog Topics"}),"\n",(0,n.jsx)(t.p,{children:"These topics store the complete state of your state stores. Every change to a state store is logged to its corresponding changelog topic.\nThe naming pattern is:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"<application.id>-<store-name>-changelog\n"})}),"\n",(0,n.jsx)(t.h3,{id:"repartition-topics",children:"Repartition Topics"}),"\n",(0,n.jsx)(t.p,{children:"Created when data needs to be repartitioned for operations like joins or aggregations. The naming pattern is:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"<application.id>-<operation>-repartition\n"})}),"\n",(0,n.jsxs)(t.admonition,{type:"danger",children:[(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Here's the problem"}),": if you don't give your state stores names, Kafka Streams will make up names automatically.\nBut these automatic names can change when you update your code or Kafka Streams version, and that means you'll past data."]}),(0,n.jsxs)(t.p,{children:["For example, let's say you have an app that joins a ",(0,n.jsx)(t.code,{children:"KTable"})," with a ",(0,n.jsx)(t.code,{children:"KStream"}),". If you redeploy your app and the changelog topic gets a new name,\nyou'll lose all the data that was stored in your ",(0,n.jsx)(t.code,{children:"KTable"}),". Your joins will stop working because the old data is gone."]})]}),"\n",(0,n.jsx)(t.h2,{id:"code-examples",children:"Code Examples"}),"\n",(0,n.jsx)(t.p,{children:"Let's take a common code example. If you do these operations in Kafka Streams:"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["Create a ",(0,n.jsx)(t.code,{children:"KStream"})," from a topic"]}),"\n",(0,n.jsxs)(t.li,{children:["Do a stateless operation like ",(0,n.jsx)(t.code,{children:"map"})," or ",(0,n.jsx)(t.code,{children:"filter"})]}),"\n",(0,n.jsxs)(t.li,{children:["Create a ",(0,n.jsx)(t.code,{children:"KTable"})," from this ",(0,n.jsx)(t.code,{children:"KStream"})]}),"\n",(0,n.jsxs)(t.li,{children:["Perform a left join with another ",(0,n.jsx)(t.code,{children:"KStream"})]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"In code, it will look like this:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'    val sourceStream: KStream[String, A] = builder.stream[String, A]("test-topic")\n    val mappedStream: KStream[String, B] = sourceStream.map { (key, value) =>\n      // assume some transformation logic\n      val transformedValue = ???\n      (key, transformedValue)\n    }\n    // .toTable will create a state store\n    val kTable: KTable[String, String] = mappedStream.toTable\n    val secondStream: KStream[String, C] = builder.stream[String, B]("test-topic-2")\n    val joinedStream: KStream[String, D] = secondStream.leftJoin(kTable) { (streamValue, tableValue) =>\n      // Join logic\n      ???\n    }\n'})}),"\n",(0,n.jsx)(t.p,{children:"When this code runs:"}),"\n",(0,n.jsxs)(t.ol,{children:["\n",(0,n.jsx)(t.li,{children:"Kafka Streams creates a state store to maintain the current state of the topic"}),"\n",(0,n.jsxs)(t.li,{children:["A changelog topic ",(0,n.jsx)(t.code,{children:"my-application-KSTREAM-TOTABLE-STATE-STORE-0000000007-changelog"})," is created"]}),"\n",(0,n.jsx)(t.li,{children:"Every update to the KTable updates both the local state store and the changelog topic"}),"\n",(0,n.jsx)(t.li,{children:"If the application restarts, the state store is rebuilt from the changelog topic"}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["But now, what happens if we modify the code? For example, the ",(0,n.jsx)(t.code,{children:"map"})," operation?\nKafka Streams will think it's a new ",(0,n.jsx)(t.code,{children:"KTable"})," and it will create a new state store with a new name, like this:"]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.code,{children:"my-application-KSTREAM-TOTABLE-STATE-STORE-0000000042-changelog"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:["When the application restarts, it will rebuild the ",(0,n.jsx)(t.code,{children:"KTable"})," in memory using the data from the new changelog topic,\nbut the old data will be lost, as it was stored in the previous changelog topic.\nPractically speaking, we have lost all the previous data in the ",(0,n.jsx)(t.code,{children:"KTable"}),".\nNow, new records in the ",(0,n.jsx)(t.code,{children:"KStream"})," that try to find a match on data processed before our re-deployment will not find it, leading to missing results."]}),"\n",(0,n.jsx)(t.h2,{id:"naming-state-stores",children:"Naming State Stores"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"The solution is simple"}),": give your state stores names."]}),"\n",(0,n.jsxs)(t.p,{children:["You can (and you should) provide explicit names for your state stores using the ",(0,n.jsx)(t.code,{children:"Materialized"})," class."]}),"\n",(0,n.jsx)(t.p,{children:"The above example can be modified to use explicit names for the state store:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'    val kTable: KTable[String, String] = mappedStream.toTable(\n      Materialized.as("my-stream-TOTABLE-my-table-name")\n    )\n'})}),"\n",(0,n.jsx)(t.p,{children:"Full example:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'    val sourceStream: KStream[String, A] = builder.stream[String, A]("test-topic")\n    val mappedStream: KStream[String, String] = sourceStream.map { (key, value) =>\n      // assume some transformation logic\n      val transformedValue = ???\n      (key, transformedValue)\n    }\n    // .toTable will create a state store, now with an explicit name\n    val kTable: KTable[String, String] = mappedStream.toTable(\n      Materialized.as[String, String]("my-stream-TOTABLE-my-table-name")\n    )\n    val secondStream: KStream[String, B] = builder.stream[String, B]("test-topic-2")\n    val joinedStream: KStream[String, C] = secondStream.leftJoin(kTable) { (streamValue, tableValue) =>\n      // Join logic\n      ???\n    }\n'})}),"\n",(0,n.jsx)(t.admonition,{type:"warning",children:(0,n.jsxs)(t.p,{children:["Note that the ",(0,n.jsx)(t.code,{children:"Materialized"})," class has other methods, like ",(0,n.jsx)(t.code,{children:"Materialized.with"}),", which allow you to specify some configuration, but not the name of the state store."]})}),"\n",(0,n.jsx)(t.admonition,{type:"warning",children:(0,n.jsxs)(t.p,{children:["Also, note that the class ",(0,n.jsx)(t.code,{children:"Named"}),", which you can use like ",(0,n.jsx)(t.code,{children:'Named.as("my-name")'}),", is not the same as ",(0,n.jsx)(t.code,{children:'Materialized.as("my-name")'}),",\n",(0,n.jsx)(t.code,{children:"Named"})," gives a name to the operation, not to the state store. This might work for other topics like ",(0,n.jsx)(t.code,{children:"*-repartition"})," topics, but it does not affect state stores."]})}),"\n",(0,n.jsx)(t.p,{children:"More options can be set on a State Store, a bigger example would be:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-scala",children:'stream.toTable(\n        Named.as(s"TABLE-table-name"),\n        Materialized\n          .as[K, V, ByteArrayKeyValueStore](s"TABLE-table-name")\n          .withKeySerde(keySerde)\n          .withValueSerde(valueSerde)\n          .withStoreType(storeType)\n      )\n'})}),"\n",(0,n.jsxs)(t.p,{children:["The same problem happens with other operations like ",(0,n.jsx)(t.code,{children:"aggregate"}),"."]}),"\n",(0,n.jsx)(t.p,{children:"Without explicit naming, Kafka Streams generates names like:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"KSTREAM-AGGREGATE-STATE-STORE-0000000003\n"})}),"\n",(0,n.jsx)(t.p,{children:"The corresponding changelog topic would be:"}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{children:"my-app-KSTREAM-AGGREGATE-STATE-STORE-0000000003-changelog\n"})}),"\n",(0,n.jsx)(t.p,{children:"Which after a re-deployment, if the state store name changes, will lead to wrong aggregation results."}),"\n",(0,n.jsx)(t.admonition,{type:"tip",children:(0,n.jsxs)(t.p,{children:["Use descriptive names that clearly indicate what the state store contains.\nThis makes debugging, monitoring, and maintenance much easier. For example, add your operation to the name, like ",(0,n.jsx)(t.code,{children:"TOTABLE"}),",\nor ",(0,n.jsx)(t.code,{children:"AGGREGATE"})," plus any additional context that helps you understand the purpose of the state store."]})}),"\n",(0,n.jsx)(t.h3,{id:"benefits-of-named-state-stores",children:"Benefits of Named State Stores"}),"\n",(0,n.jsxs)(t.p,{children:["We could list several benefits, but among them, the most important one is: ",(0,n.jsx)(t.strong,{children:"You won't lose data silently"}),"."]}),"\n",(0,n.jsx)(t.h2,{id:"tldr",children:"TL;DR"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Always name your state stores, or you'll lose data without knowing it."}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:["If you think this might be already happening to you, check all the topics named like ",(0,n.jsx)(t.code,{children:"*-changelog"})," in your Kafka cluster,\nand check if any of them has outdated data, it could potentially indicate that a state store was renamed at some point,\nleaving a ",(0,n.jsx)(t.code,{children:"*-changelog"})," topic unused, and another one with less data than expected."]})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},28453:(e,t,a)=>{a.d(t,{R:()=>o,x:()=>r});var n=a(96540);const s={},i=n.createContext(s);function o(e){const t=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(i.Provider,{value:t},e.children)}}}]);